<!DOCTYPE html>
<html><head><meta charset="UTF-8"><link href="css/default.css" rel="stylesheet" type="text/css"><script src="js/jquery.min.js" type="text/javascript"></script><script src="js/page_effects.js" type="text/javascript"></script><title>deeplearning4clj.word2vec documentation</title></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html">Deeplearning4clj 0.1.0-SNAPSHOT API documentation</a></h1></div><div class="sidebar" id="namespaces"><h3><a href="index.html"><span class="inner">Namespaces</span></a></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>deeplearning4clj</span></div></div></li><li class="depth-2 branch"><a href="deeplearning4clj.core.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>core</span></div></a></li><li class="depth-2 current"><a href="deeplearning4clj.word2vec.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>word2vec</span></div></a></li></ul></div><div class="sidebar" id="vars"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-aggregatePreProcessor"><div class="inner"><span>aggregatePreProcessor</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-fit-and-save-model"><div class="inner"><span>fit-and-save-model</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-fit-model"><div class="inner"><span>fit-model</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-kryo"><div class="inner"><span>kryo</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-load-model"><div class="inner"><span>load-model</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-load-vectors"><div class="inner"><span>load-vectors</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-save-model"><div class="inner"><span>save-model</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-save-vectors"><div class="inner"><span>save-vectors</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-tokenize"><div class="inner"><span>tokenize</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-tokenizer"><div class="inner"><span>tokenizer</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-tokenizer-factory"><div class="inner"><span>tokenizer-factory</span></div></a></li><li class="depth-1"><a href="deeplearning4clj.word2vec.html#var-word2vec"><div class="inner"><span>word2vec</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h2 class="anchor" id="top">deeplearning4clj.word2vec</h2><div class="doc"><pre class="plaintext"></pre></div><div class="public anchor" id="var-aggregatePreProcessor"><h3>aggregatePreProcessor</h3><div class="usage"><code>(aggregatePreProcessor preprocessors)</code></div><div class="doc"><pre class="plaintext">A sentence pre-processor that applies a list of pre-processors
</pre></div></div><div class="public anchor" id="var-fit-and-save-model"><h3>fit-and-save-model</h3><div class="usage"><code>(fit-and-save-model w2v output-file)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-fit-model"><h3>fit-model</h3><div class="usage"><code>(fit-model w2v)</code></div><div class="doc"><pre class="plaintext">Training a Word2Vec model.
</pre></div></div><div class="public anchor" id="var-kryo"><h3>kryo</h3><div class="usage"></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-load-model"><h3>load-model</h3><div class="usage"><code>(load-model model-name)</code></div><div class="doc"><pre class="plaintext">Load a Word2Vec model from the given name
</pre></div></div><div class="public anchor" id="var-load-vectors"><h3>load-vectors</h3><div class="usage"><code>(load-vectors filename)</code></div><div class="doc"><pre class="plaintext">Load the word vectors from the given file.
</pre></div></div><div class="public anchor" id="var-save-model"><h3>save-model</h3><div class="usage"><code>(save-model w2v filename)</code></div><div class="doc"><pre class="plaintext">Save a Word2Vec model to the given file.
</pre></div></div><div class="public anchor" id="var-save-vectors"><h3>save-vectors</h3><div class="usage"><code>(save-vectors w2v filename)</code></div><div class="doc"><pre class="plaintext">Save just the word vectors from the given model.
</pre></div></div><div class="public anchor" id="var-tokenize"><h3>tokenize</h3><div class="usage"><code>(tokenize s)</code></div><div class="doc"><pre class="plaintext">Tokenize on white space, only return tokens longer than 2 and replace tokens of the form #d+ with the string HASHNUM.
</pre></div></div><div class="public anchor" id="var-tokenizer"><h3>tokenizer</h3><div class="usage"><code>(tokenizer tokenizer-fn s)</code></div><div class="doc"><pre class="plaintext">A tokenizer which utilizes a given function to perform the tokenization of the string.
</pre></div></div><div class="public anchor" id="var-tokenizer-factory"><h3>tokenizer-factory</h3><div class="usage"><code>(tokenizer-factory tokenizer-fn)</code></div><div class="doc"><pre class="plaintext">Tokenizer factory that creates a tokenizer using the given function.
</pre></div></div><div class="public anchor" id="var-word2vec"><h3>word2vec</h3><div class="usage"><code>(word2vec sent-iter tok {:keys [batch-size min-freq layer-size window-size], :or {batch-size 1000, min-freq 5, layer-size 300, window-size 5}})</code></div><div class="doc"><pre class="plaintext">Create a Deeplearning4j Word2Vec object which uses the provided sentence iterator and tokenizer.
</pre></div></div></div></body></html>